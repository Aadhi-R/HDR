# -*- coding: utf-8 -*-
"""HDR using DenseNet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Srrhj19jZfIijG1vlOh_e-sw_JrjMbv7
"""

from matplotlib import pyplot as plt
from sklearn.model_selection import KFold
from tensorflow.keras.datasets import mnist
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import MaxPooling2D
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import Flatten
from tensorflow.keras.optimizers import SGD
import numpy as np
from numpy import mean
from numpy import std

# load train and test dataset
def load_dataset():
	# load dataset
	(trainX, trainY), (testX, testY) = mnist.load_data()
	# reshape dataset to have a single channel
	trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))
	testX = testX.reshape((testX.shape[0], 28, 28, 1))
	# one hot encode target values
	trainY = to_categorical(trainY)
	testY = to_categorical(testY)

	return trainX, trainY, testX, testY

# scale pixels
def prep_pixels(train, test):
	# convert from integers to floats
	train_norm = train.astype('float32')
	test_norm = test.astype('float32')
	# normalize to range 0-1
	train_norm = train_norm / 255.0
	test_norm = test_norm / 255.0
	# return normalized images
	return train_norm, test_norm

import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Dense
from tensorflow.keras.layers import AvgPool2D, GlobalAveragePooling2D, MaxPool2D
from tensorflow.keras.models import Model
from tensorflow.keras.layers import ReLU, concatenate
import tensorflow.keras.backend as K

def densenet(input_shape, n_classes, filters = 32):
  #batchnorm + relu + conv
  def bn_rl_conv(x, filters, kernel = 1, strides = 1):

    x = BatchNormalization() (x)
    x = ReLU() (x)
    x = Conv2D(filters, kernel, strides = strides, padding = 'same') (x)
    
    return x

  def dense_block(x, repetition):

    for _ in range(repetition):

      y = bn_rl_conv(x, 4*filters)
      y = bn_rl_conv(y, filters, 3)
      x = concatenate([y,x])

      return x 

  def transition_layer(x):

    x = bn_rl_conv(x, K.int_shape(x) [-1] // 2)   
    x = AvgPool2D(2, strides = 2, padding = 'same') (x)
    return x

  input = Input (input_shape)  
  x = Conv2D(64, 7, strides = 2, padding = 'same') (input)
  x = MaxPool2D(3, strides = 2, padding = 'same') (x)

  for repetition in [3,6,6,3]:

    d = dense_block(x, repetition)
    x = transition_layer(d)

  x = GlobalAveragePooling2D() (d)
  output = Dense(n_classes, activation = 'softmax') (x)

  model = Model(input, output)
  return model

input_shape = 28, 28, 1  
n_classes = 10

model = densenet(input_shape, n_classes)
model.summary()

trainX, trainY, testX, testY = load_dataset()
trainX, trainY = prep_pixels(trainX, trainY)
testX, testY = prep_pixels(testX, testY)

from keras.utils import np_utils
#trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))
#testX = testX.reshape((testX.shape[0], 28, 28, 1))

trainX_reshaped=np.reshape(trainX,(60000, 28, 28))
testX_reshaped=np.reshape(testX,(10000, 28, 28))

#train_norm = train.astype('float32')
#test_norm = test.astype('float32')

#train_norm = train_norm / 255.0
#test_norm = test_norm / 255.0
 
cat_test_y = np_utils.to_categorical(testY)
trainY = np_utils.to_categorical(trainY)

print("X_train shape : ",trainX.shape)
print("y_train shape : ",trainY.shape)
print("X_test shape : ",testX.shape)
print("y_test shape : ",testY.shape)

from tensorflow.keras.optimizers import Adam
batch_size = 32
epochs = 10
optimizer = Adam(lr = 0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)
model.compile(optimizer = optimizer, loss= 'categorical_crossentropy', metrics = ['accuracy'])
history = model.fit(trainX, trainY, epochs=epochs, batch_size=batch_size, shuffle = True, validation_data = (testX, testY))

dense_block_size = 3
layers_in_block = 4

growth_rate = 12
classes = 10
model = densenet((60000, 28, 28), 10, filters = 32 )
model.summary()

model.save('model.h5')

predictions = model.predict(testX)

print(predictions[0])

a = testX[0]
b = testY[0]

print("a =", predictions[0])
print("b =", b)

ans = np.argmax(predictions[0])
print(ans)

(_a, _b), (tX, tY) = mnist.load_data()

from PIL import Image
img = Image.fromarray(tX[0])

display(img)

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(testX, predictions)

import pandas as pd 

import matplotlib.pyplot as plt
pd.DataFrame(history.history).plot(figsize=(8, 5))

pd.DataFrame(history.history)[['loss', 'val_loss']].plot(figsize=(8, 5))
plt.show()

from keras.models import load_model
model = load_model('model.h5')

model.summary()

